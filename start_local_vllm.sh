#!/bin/bash
# å¿«é€Ÿå¯åŠ¨æœ¬åœ° vLLM æœåŠ¡

MODEL_PATH="models/Qwen--Qwen2.5-7B-Instruct"
PORT=8000

echo "ğŸš€ å¯åŠ¨æœ¬åœ° vLLM æœåŠ¡"
echo "   æ¨¡å‹: $MODEL_PATH"
echo "   ç«¯å£: $PORT"
echo ""

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
if [ ! -d "$MODEL_PATH" ]; then
    echo "âŒ æ¨¡å‹ä¸å­˜åœ¨: $MODEL_PATH"
    echo ""
    echo "è¯·å…ˆä¸‹è½½æ¨¡å‹ï¼š"
    echo "  python scripts/download_model.py --model Qwen/Qwen2.5-7B-Instruct --output models/"
    exit 1
fi

# å¯åŠ¨æœåŠ¡ï¼ˆä½¿ç”¨ --enforce-eager é¿å… duplicate template name é”™è¯¯ï¼‰
# ä½¿ç”¨ 70% GPU å†…å­˜åˆ©ç”¨ç‡ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜ç”¨äº KV cache
echo "âš ï¸  ä½¿ç”¨ --enforce-eager æ¨¡å¼ï¼ˆé¿å… duplicate template name é”™è¯¯ï¼‰"
echo "   ä½¿ç”¨ 70% GPU å†…å­˜åˆ©ç”¨ç‡ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜ç”¨äº KV cacheï¼‰"
echo ""

python scripts/launch_vllm_server.py --model "$MODEL_PATH" --port $PORT --enforce-eager --gpu-memory-utilization 0.7

