#!/usr/bin/env python3
"""
å¯¹æ¯”æµ‹è¯•è„šæœ¬
åŒæ—¶è¿è¡Œå¢å¼ºç‰ˆå’ŒåŸºçº¿ç‰ˆï¼Œç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.benchmark.auto_player import AutoPlayer
from scripts.benchmark.baseline_auto_player import BaselineAutoPlayer

console = Console()


class ComparisonTest:
    """å¯¹æ¯”æµ‹è¯•ç±»"""
    
    def __init__(self, model_path: str = None):
        """
        åˆå§‹åŒ–å¯¹æ¯”æµ‹è¯•
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„æˆ–åç§°ï¼ˆå¦‚æœä¸º Noneï¼Œä»é…ç½®è¯»å–ï¼‰
        """
        from src.config import get_settings
        
        settings = get_settings()
        
        # å¦‚æœæœªæŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œä»é…ç½®è¯»å–ï¼ˆä¸è®¾ç½®é»˜è®¤å€¼ï¼‰
        if model_path is None:
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„é…ç½®é¡¹ VLLM_MODELï¼Œå…¶æ¬¡ä½¿ç”¨å·²åºŸå¼ƒçš„ VLLM_MODEL_PATH
            self.model_path = settings.vllm_model or settings.vllm_model_path
        else:
            self.model_path = model_path
        
        self.enhanced_results = {}
        self.baseline_results = {}
    
    def run_enhanced(self) -> Dict[str, Any]:
        """è¿è¡Œå¢å¼ºç‰ˆæµ‹è¯•ï¼ˆä½¿ç”¨ vLLMï¼‰"""
        console.print("\n[bold green]ğŸš€ è¿è¡Œå¢å¼ºç‰ˆï¼ˆRAGEnhancedAgentMemory + vLLMï¼‰[/bold green]")
        
        # ç¡®ä¿æ¨¡å‹è·¯å¾„å·²è®¾ç½®
        if not self.model_path:
            console.print("[red]âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„æœªè®¾ç½®[/red]")
            console.print("[yellow]æç¤º: è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æŒ‡å®šæ¨¡å‹ï¼š[/yellow]")
            console.print("[dim]  1. å‘½ä»¤è¡Œå‚æ•°: --model-path <model-name>[/dim]")
            console.print("[dim]  2. ç¯å¢ƒå˜é‡: åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® VLLM_MODEL=<model-name>[/dim]")
            console.print("[dim]  3. å¦‚æœä½¿ç”¨ DeepSeek APIï¼Œè®¾ç½® VLLM_MODEL=deepseek-chat[/dim]")
            raise ValueError("æ¨¡å‹è·¯å¾„æœªè®¾ç½®ï¼Œæ— æ³•è¿è¡Œå¢å¼ºç‰ˆæµ‹è¯•")
        
        player = AutoPlayer(
            model_path=self.model_path,
            use_baseline=False  # ä½¿ç”¨ vLLM
        )
        
        # è·å–åˆå§‹å­˜å‚¨çŠ¶æ€
        mem_stats_start = player.agent.long_term_memory.get_stats()
        start_count = mem_stats_start.get("total_memories", 0)
        
        # è¿è¡Œæµ‹è¯•
        player.run()
        
        # è·å–æœ€ç»ˆå­˜å‚¨çŠ¶æ€
        mem_stats_end = player.agent.long_term_memory.get_stats()
        end_count = mem_stats_end.get("total_memories", 0)
        actual_stored = end_count - start_count
        total_turns = len(player.generate_script())
        reduction_rate = (1 - (actual_stored / total_turns)) * 100 if total_turns > 0 else 0
        
        # è®¡ç®—ä¿¡æ¯ä¿ç•™ç‡
        theoretical_effective = 20
        retention_rate = (actual_stored / theoretical_effective * 100) if theoretical_effective > 0 else 0
        if actual_stored > theoretical_effective:
            retention_rate = 100.0
        
        # æå–ç»“æœ
        results = {
            "latencies": player.latencies,
            "ttfts": player.ttfts,
            "tokens_per_second": player.tokens_per_second,
            "tokens_generated": player.tokens_generated,
            "recall_test_cases": player.recall_test_cases,
            "session_id": player.session_id,
            "stored_turns": actual_stored,
            "total_turns": total_turns,
            "noise_filter_rate": reduction_rate,
            "retention_rate": retention_rate,
        }
        
        # æ¸…ç†
        player.agent.close()
        
        # å¢å¼ºç‰ˆæµ‹è¯•ç»“æŸåï¼Œè‡ªåŠ¨å…³é—­ vLLM æœåŠ¡ï¼ˆé‡Šæ”¾ GPU å†…å­˜ç»™åŸºçº¿ç³»ç»Ÿä½¿ç”¨ï¼‰
        self._shutdown_vllm_service()
        
        return results
    
    def _shutdown_vllm_service(self):
        """
        å…³é—­æœ¬åœ° vLLM æœåŠ¡ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
        
        é€šè¿‡æ£€æŸ¥é…ç½®ä¸­çš„ base_url æ˜¯å¦ä¸ºæœ¬åœ°æœåŠ¡æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦å…³é—­
        """
        try:
            import subprocess
            import psutil
            from src.config import get_settings
            
            settings = get_settings()
            base_url = settings.vllm_base_url
            
            # åªå…³é—­æœ¬åœ° vLLM æœåŠ¡ï¼Œä¸å…³é—­äº‘ç«¯ API
            if not base_url or not ("localhost" in base_url.lower() or "127.0.0.1" in base_url.lower()):
                return
            
            console.print("\n[yellow]ğŸ”„ æ­£åœ¨å…³é—­ vLLM æœåŠ¡ï¼ˆé‡Šæ”¾ GPU å†…å­˜ï¼‰...[/yellow]")
            
            # æŸ¥æ‰¾ vLLM ç›¸å…³è¿›ç¨‹
            vllm_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline:
                        cmdline_str = ' '.join(cmdline).lower()
                        # æŸ¥æ‰¾ vLLM ç›¸å…³è¿›ç¨‹
                        if 'vllm' in cmdline_str or 'enginecore' in cmdline_str:
                            vllm_processes.append(proc)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if not vllm_processes:
                console.print("[dim]æœªæ‰¾åˆ°è¿è¡Œä¸­çš„ vLLM æœåŠ¡è¿›ç¨‹[/dim]")
                return
            
            # å…³é—­æ‰€æœ‰ vLLM è¿›ç¨‹
            for proc in vllm_processes:
                try:
                    pid = proc.info['pid']
                    console.print(f"[dim]å…³é—­è¿›ç¨‹ {pid}...[/dim]")
                    proc.terminate()  # ä¼˜é›…å…³é—­
                    
                    # ç­‰å¾…è¿›ç¨‹ç»“æŸï¼ˆæœ€å¤š 5 ç§’ï¼‰
                    try:
                        proc.wait(timeout=5)
                        console.print(f"[green]âœ“ è¿›ç¨‹ {pid} å·²å…³é—­[/green]")
                    except psutil.TimeoutExpired:
                        # å¦‚æœä¼˜é›…å…³é—­å¤±è´¥ï¼Œå¼ºåˆ¶å…³é—­
                        console.print(f"[yellow]è¿›ç¨‹ {pid} æœªå“åº”ï¼Œå¼ºåˆ¶å…³é—­...[/yellow]")
                        proc.kill()
                        proc.wait(timeout=2)
                        console.print(f"[green]âœ“ è¿›ç¨‹ {pid} å·²å¼ºåˆ¶å…³é—­[/green]")
                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                    console.print(f"[dim]æ— æ³•å…³é—­è¿›ç¨‹: {e}[/dim]")
            
            # ç­‰å¾… GPU å†…å­˜é‡Šæ”¾ï¼ˆç»™ç³»ç»Ÿä¸€ç‚¹æ—¶é—´ï¼‰
            time.sleep(2)
            
            console.print("[green]âœ… vLLM æœåŠ¡å·²å…³é—­ï¼ŒGPU å†…å­˜å·²é‡Šæ”¾[/green]")
            console.print("[dim]åŸºçº¿ç³»ç»Ÿç°åœ¨å¯ä»¥ä½¿ç”¨ GPU è¿›è¡Œæ¨ç†[/dim]\n")
            
        except ImportError:
            console.print("[yellow]âš ï¸ psutil æœªå®‰è£…ï¼Œæ— æ³•è‡ªåŠ¨å…³é—­ vLLM æœåŠ¡[/yellow]")
            console.print("[dim]è¯·æ‰‹åŠ¨å…³é—­ vLLM æœåŠ¡ï¼Œæˆ–å®‰è£… psutil: pip install psutil[/dim]")
        except Exception as e:
            console.print(f"[yellow]âš ï¸ å…³é—­ vLLM æœåŠ¡æ—¶å‡ºé”™: {e}[/yellow]")
            console.print("[dim]è¯·æ‰‹åŠ¨å…³é—­ vLLM æœåŠ¡[/dim]")
    
    def run_baseline(self) -> Dict[str, Any]:
        """è¿è¡ŒåŸºçº¿ç‰ˆæµ‹è¯•ï¼ˆä½¿ç”¨æ»‘åŠ¨çª—å£è®°å¿† + BaselineInferenceï¼‰"""
        console.print("\n[bold yellow]ğŸ“Š è¿è¡ŒåŸºçº¿ç‰ˆï¼ˆæ»‘åŠ¨çª—å£è®°å¿† + BaselineInferenceï¼‰[/bold yellow]")
        console.print("[dim]æ³¨æ„: åŸºçº¿ç³»ç»Ÿä½¿ç”¨ç®€å•çš„æ»‘åŠ¨çª—å£è®°å¿†ï¼ˆä¸ä½¿ç”¨ RAGEnhancedAgentMemoryï¼‰ï¼Œä½†ä½¿ç”¨ä¸å¢å¼ºç‰ˆç›¸åŒçš„æ¨¡å‹[/dim]")
        
        # BaselineInference ç°åœ¨æ”¯æŒ API æ¨¡å¼ï¼Œå¯ä»¥ä½¿ç”¨ä¸å¢å¼ºç‰ˆç›¸åŒçš„æ¨¡å‹
        # åŸºçº¿ç³»ç»Ÿä½¿ç”¨ä¸å¢å¼ºç‰ˆç›¸åŒçš„æ¨¡å‹é…ç½®
        baseline_model_path = self.model_path
        
        # ç¡®ä¿æ¨¡å‹è·¯å¾„å·²è®¾ç½®
        if not baseline_model_path:
            console.print("[red]âŒ é”™è¯¯: åŸºçº¿ç³»ç»Ÿæ¨¡å‹è·¯å¾„æœªè®¾ç½®[/red]")
            console.print("[yellow]æç¤º: è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æŒ‡å®šæ¨¡å‹ï¼š[/yellow]")
            console.print("[dim]  1. å‘½ä»¤è¡Œå‚æ•°: --model-path <model-name> æˆ– <local-path>[/dim]")
            console.print("[dim]  2. ç¯å¢ƒå˜é‡: åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® VLLM_MODEL=<model-name>[/dim]")
            raise ValueError("åŸºçº¿ç³»ç»Ÿæ¨¡å‹è·¯å¾„æœªè®¾ç½®ï¼Œæ— æ³•è¿è¡ŒåŸºçº¿ç‰ˆæµ‹è¯•")
        
        player = BaselineAutoPlayer(
            model_path=baseline_model_path,
            window_size=10
        )
        
        # è·å–åˆå§‹çŠ¶æ€ï¼ˆåŸºçº¿ç³»ç»Ÿä½¿ç”¨æ»‘åŠ¨çª—å£ï¼‰
        start_history_size = len(player.agent.conversation_history)
        
        # è¿è¡Œæµ‹è¯•
        player.run()
        
        # è·å–æœ€ç»ˆçŠ¶æ€
        end_history_size = len(player.agent.conversation_history)
        stats = player.agent.get_stats()
        total_turns = len(player.generate_script())
        stored_turns = end_history_size
        lost_turns = total_turns - stored_turns
        
        # è®¡ç®—å­˜å‚¨ç»Ÿè®¡
        # åŸºçº¿ç³»ç»Ÿï¼šæ‰€æœ‰å¯¹è¯éƒ½ä¿å­˜åœ¨çª—å£å†…ï¼ˆè¶…å‡ºçª—å£çš„ä¸¢å¤±ï¼‰
        # å™ªéŸ³è¿‡æ»¤ç‡ï¼šåŸºçº¿ç³»ç»Ÿæ²¡æœ‰è¿‡æ»¤ï¼Œæ‰€ä»¥è¿‡æ»¤ç‡ä¸º0
        noise_filter_rate = 0.0
        
        # ä¿¡æ¯ä¿ç•™ç‡ï¼šåªä¿ç•™çª—å£å†…çš„å¯¹è¯
        retention_rate = (stored_turns / total_turns * 100) if total_turns > 0 else 0
        
        # æå–ç»“æœï¼ˆä¸å¢å¼ºç‰ˆç›¸åŒçš„æŒ‡æ ‡ï¼‰
        results = {
            "latencies": player.latencies,
            "ttfts": player.ttfts,
            "tokens_per_second": player.tokens_per_second,
            "tokens_generated": player.tokens_generated,
            "recall_test_cases": player.recall_test_cases,
            "session_id": player.session_id,
            "stored_turns": stored_turns,
            "total_turns": total_turns,
            "noise_filter_rate": noise_filter_rate,
            "retention_rate": retention_rate,
            "window_size": stats.get("window_size", 10),
        }
        
        # æ¸…ç†
        player.close()
        
        return results
    
    def generate_comparison_report(self, enhanced: Dict[str, Any], baseline: Dict[str, Any]):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        import statistics
        
        console.print("\n\n")
        console.rule("[bold cyan]ğŸ“Š å¢å¼ºç‰ˆ vs åŸºçº¿ç‰ˆ å¯¹æ¯”æŠ¥å‘Š[/bold cyan]")
        
        # 1. æ€§èƒ½å¯¹æ¯”
        enhanced_avg_latency = statistics.mean(enhanced["latencies"]) if enhanced["latencies"] else 0
        baseline_avg_latency = statistics.mean(baseline["latencies"]) if baseline["latencies"] else 0
        
        enhanced_avg_ttft = statistics.mean(enhanced["ttfts"]) if enhanced["ttfts"] else 0
        baseline_avg_ttft = statistics.mean(baseline["ttfts"]) if baseline["ttfts"] else 0
        
        perf_table = Table(title="âš¡ æ¨ç†æ€§èƒ½å¯¹æ¯”")
        perf_table.add_column("æŒ‡æ ‡", style="cyan")
        perf_table.add_column("å¢å¼ºç‰ˆ", style="green")
        perf_table.add_column("åŸºçº¿ç‰ˆ", style="yellow")
        perf_table.add_column("å·®å¼‚", style="magenta")
        
        latency_diff = ((enhanced_avg_latency - baseline_avg_latency) / baseline_avg_latency * 100) if baseline_avg_latency > 0 else 0
        perf_table.add_row(
            "å¹³å‡å»¶è¿Ÿ",
            f"{enhanced_avg_latency:.1f} ms",
            f"{baseline_avg_latency:.1f} ms",
            f"{latency_diff:+.1f}%"
        )
        
        if enhanced_avg_ttft > 0 and baseline_avg_ttft > 0:
            ttft_diff = ((enhanced_avg_ttft - baseline_avg_ttft) / baseline_avg_ttft * 100)
            perf_table.add_row(
                "å¹³å‡é¦–å­—å»¶è¿Ÿ (TTFT)",
                f"{enhanced_avg_ttft:.1f} ms",
                f"{baseline_avg_ttft:.1f} ms",
                f"{ttft_diff:+.1f}%"
            )
        
        # ååé‡æŒ‡æ ‡
        enhanced_avg_tps = statistics.mean(enhanced.get("tokens_per_second", [])) if enhanced.get("tokens_per_second") else 0
        baseline_avg_tps = statistics.mean(baseline.get("tokens_per_second", [])) if baseline.get("tokens_per_second") else 0
        
        if enhanced_avg_tps > 0 and baseline_avg_tps > 0:
            tps_diff = ((enhanced_avg_tps - baseline_avg_tps) / baseline_avg_tps * 100)
            perf_table.add_row(
                "å¹³å‡ååé‡",
                f"{enhanced_avg_tps:.1f} tokens/s",
                f"{baseline_avg_tps:.1f} tokens/s",
                f"{tps_diff:+.1f}%"
            )
        
        console.print(perf_table)
        console.print("\n")
        
        # 2. å¬å›èƒ½åŠ›å¯¹æ¯”
        enhanced_recall_count = sum(1 for case in enhanced["recall_test_cases"].values() if case["found"])
        baseline_recall_count = sum(1 for case in baseline["recall_test_cases"].values() if case["found"])
        
        enhanced_recall_rate = (enhanced_recall_count / len(enhanced["recall_test_cases"])) * 100
        baseline_recall_rate = (baseline_recall_count / len(baseline["recall_test_cases"])) * 100
        
        recall_table = Table(title="ğŸ§  é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›å¯¹æ¯”")
        recall_table.add_column("æµ‹è¯•é¡¹", style="cyan")
        recall_table.add_column("å¢å¼ºç‰ˆ", style="green")
        recall_table.add_column("åŸºçº¿ç‰ˆ", style="yellow")
        recall_table.add_column("æ”¹è¿›", style="magenta")
        
        for test_name in enhanced["recall_test_cases"].keys():
            enhanced_found = enhanced["recall_test_cases"][test_name]["found"]
            baseline_found = baseline["recall_test_cases"][test_name]["found"]
            
            enhanced_status = "âœ…" if enhanced_found else "âŒ"
            baseline_status = "âœ…" if baseline_found else "âŒ"
            improvement = "âœ… æå‡" if (enhanced_found and not baseline_found) else ("=" if enhanced_found == baseline_found else "")
            
            recall_table.add_row(
                test_name,
                enhanced_status,
                baseline_status,
                improvement
            )
        
        recall_table.add_row(
            "[bold]å¬å›æˆåŠŸç‡[/bold]",
            f"[bold green]{enhanced_recall_rate:.1f}%[/bold green]",
            f"[bold yellow]{baseline_recall_rate:.1f}%[/bold yellow]",
            f"[bold magenta]{enhanced_recall_rate - baseline_recall_rate:+.1f} ç™¾åˆ†ç‚¹[/bold magenta]"
        )
        
        console.print(recall_table)
        console.print("\n")
        
        # 3. å­˜å‚¨ç»Ÿè®¡å¯¹æ¯”
        store_table = Table(title="ğŸ’¾ å­˜å‚¨æ•ˆç‡å¯¹æ¯”")
        store_table.add_column("æŒ‡æ ‡", style="cyan")
        store_table.add_column("å¢å¼ºç‰ˆ", style="green")
        store_table.add_column("åŸºçº¿ç‰ˆ", style="yellow")
        store_table.add_column("è¯´æ˜", style="dim")
        
        enhanced_stored = enhanced.get("stored_turns", 0)
        baseline_stored = baseline.get("stored_turns", 0)
        total_turns = enhanced.get("total_turns", 100)
        
        store_table.add_row(
            "æ•°æ®åº“ä¸­å­˜å‚¨æ•°",
            str(enhanced_stored),
            str(baseline_stored),
            "å¢å¼ºç‰ˆï¼šå‘é‡æ•°æ®åº“ï¼›åŸºçº¿ç‰ˆï¼šçª—å£å†…å¯¹è¯æ•°"
        )
        
        enhanced_noise_filter = enhanced.get("noise_filter_rate", 0)
        baseline_noise_filter = baseline.get("noise_filter_rate", 0)
        store_table.add_row(
            "å™ªéŸ³è¿‡æ»¤ç‡",
            f"{enhanced_noise_filter:.1f}%",
            f"{baseline_noise_filter:.1f}%",
            "è¢«å»é‡/è¿‡æ»¤æ‰çš„æ— æ•ˆä¿¡æ¯æ¯”ä¾‹"
        )
        
        enhanced_retention = enhanced.get("retention_rate", 0)
        baseline_retention = baseline.get("retention_rate", 0)
        store_table.add_row(
            "ä¿¡æ¯ä¿ç•™ç‡",
            f"{enhanced_retention:.1f}%",
            f"{baseline_retention:.1f}%",
            "å…³é”®ä¿¡æ¯ä¿ç•™æ¯”ä¾‹"
        )
        
        console.print(store_table)
        console.print("\n")
        
        # 4. ç»¼åˆç»“è®º
        console.rule("[bold]ğŸ“ å¯¹æ¯”ç»“è®º[/bold]")
        
        # å¬å›èƒ½åŠ›æ”¹è¿›
        recall_improvement = enhanced_recall_rate - baseline_recall_rate
        if recall_improvement > 0:
            console.print(f"âœ… [bold green]é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›æ˜¾è‘—æå‡ï¼š[/bold green] {recall_improvement:.1f} ç™¾åˆ†ç‚¹")
            console.print(f"   â€¢ å¢å¼ºç‰ˆï¼š{enhanced_recall_rate:.1f}% ({enhanced_recall_count}/{len(enhanced['recall_test_cases'])})")
            console.print(f"   â€¢ åŸºçº¿ç‰ˆï¼š{baseline_recall_rate:.1f}% ({baseline_recall_count}/{len(baseline['recall_test_cases'])})")
        else:
            console.print(f"âš ï¸ [bold yellow]å¬å›èƒ½åŠ›å¯¹æ¯”ï¼š[/bold yellow] å¢å¼ºç‰ˆ {enhanced_recall_rate:.1f}% vs åŸºçº¿ç‰ˆ {baseline_recall_rate:.1f}%")
        
        # æ€§èƒ½å¯¹æ¯”ï¼ˆvLLM vs Baselineï¼‰
        if latency_diff < -10:
            console.print(f"âœ… [bold green]vLLM ä¼˜åŒ–ç”Ÿæ•ˆï¼š[/bold green] å»¶è¿Ÿé™ä½ {abs(latency_diff):.1f}%ï¼ŒvLLM ä¼˜åŒ–æ•ˆæœæ˜¾è‘—")
        elif latency_diff < 0:
            console.print(f"âœ… [bold green]vLLM ä¼˜åŒ–ç”Ÿæ•ˆï¼š[/bold green] å»¶è¿Ÿé™ä½ {abs(latency_diff):.1f}%")
        elif abs(latency_diff) < 10:
            console.print(f"âš ï¸ [bold yellow]å»¶è¿Ÿç›¸å½“ï¼š[/bold yellow] å¢å¼ºç‰ˆå»¶è¿Ÿ {latency_diff:+.1f}%ï¼ˆå¯èƒ½å—æ£€ç´¢å¼€é”€å½±å“ï¼‰")
        else:
            console.print(f"âš ï¸ [bold yellow]å¢å¼ºç‰ˆå»¶è¿Ÿè¾ƒé«˜ï¼š[/bold yellow] +{latency_diff:.1f}%ï¼ˆæ£€ç´¢å¼€é”€ï¼Œä½†æ¢å–é•¿æœŸè®°å¿†èƒ½åŠ›ï¼‰")
        
        # TTFT å¯¹æ¯”
        if enhanced_avg_ttft > 0 and baseline_avg_ttft > 0:
            ttft_diff = ((enhanced_avg_ttft - baseline_avg_ttft) / baseline_avg_ttft * 100)
            if ttft_diff < -10:
                console.print(f"âœ… [bold green]vLLM é¦–å­—å»¶è¿Ÿä¼˜åŒ–æ˜¾è‘—ï¼š[/bold green] TTFT é™ä½ {abs(ttft_diff):.1f}%")
            elif ttft_diff < 0:
                console.print(f"âœ… [bold green]vLLM é¦–å­—å»¶è¿Ÿä¼˜åŒ–ï¼š[/bold green] TTFT é™ä½ {abs(ttft_diff):.1f}%")
        
        # æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“
        console.print("\n[bold cyan]ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“ï¼š[/bold cyan]")
        if enhanced_recall_rate > baseline_recall_rate:
            console.print("  âœ… é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›ï¼šæ˜¾è‘—ä¼˜äºåŸºçº¿ç³»ç»Ÿ")
        if enhanced_recall_rate >= 66:
            console.print("  âœ… èƒ½å¤Ÿä»é•¿æœŸè®°å¿†ä¸­å¬å›æ—©æœŸå…³é”®ä¿¡æ¯")
        if baseline_recall_rate < 33:
            console.print("  âœ… åŸºçº¿ç³»ç»Ÿæ— æ³•å¬å›è¶…å‡ºçª—å£çš„æ—©æœŸä¿¡æ¯ï¼ˆéªŒè¯äº†é—®é¢˜å­˜åœ¨ï¼‰")
        
        console.print()
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(enhanced, baseline)
    
    def generate_markdown_report(self, enhanced: Dict[str, Any], baseline: Dict[str, Any]):
        """ç”ŸæˆMarkdownæ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š"""
        import statistics
        from datetime import datetime
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        enhanced_avg_latency = statistics.mean(enhanced["latencies"]) if enhanced["latencies"] else 0
        baseline_avg_latency = statistics.mean(baseline["latencies"]) if baseline["latencies"] else 0
        enhanced_avg_ttft = statistics.mean(enhanced["ttfts"]) if enhanced["ttfts"] else 0
        baseline_avg_ttft = statistics.mean(baseline["ttfts"]) if baseline["ttfts"] else 0
        
        enhanced_avg_tps = statistics.mean(enhanced.get("tokens_per_second", [])) if enhanced.get("tokens_per_second") else 0
        baseline_avg_tps = statistics.mean(baseline.get("tokens_per_second", [])) if baseline.get("tokens_per_second") else 0
        
        enhanced_total_tokens = sum(enhanced.get("tokens_generated", [])) if enhanced.get("tokens_generated") else 0
        baseline_total_tokens = sum(baseline.get("tokens_generated", [])) if baseline.get("tokens_generated") else 0
        
        enhanced_recall_count = sum(1 for case in enhanced["recall_test_cases"].values() if case["found"])
        baseline_recall_count = sum(1 for case in baseline["recall_test_cases"].values() if case["found"])
        enhanced_recall_rate = (enhanced_recall_count / len(enhanced["recall_test_cases"])) * 100 if enhanced["recall_test_cases"] else 0
        baseline_recall_rate = (baseline_recall_count / len(baseline["recall_test_cases"])) * 100 if baseline["recall_test_cases"] else 0
        
        latency_diff = ((enhanced_avg_latency - baseline_avg_latency) / baseline_avg_latency * 100) if baseline_avg_latency > 0 else 0
        ttft_diff = ((enhanced_avg_ttft - baseline_avg_ttft) / baseline_avg_ttft * 100) if baseline_avg_ttft > 0 else 0
        tps_diff = ((enhanced_avg_tps - baseline_avg_tps) / baseline_avg_tps * 100) if baseline_avg_tps > 0 else 0
        recall_improvement = enhanced_recall_rate - baseline_recall_rate
        
        # ç”ŸæˆMarkdownå†…å®¹
        md_content = f"""# RAGEnhancedAgentMemory å¯¹æ¯”å®éªŒæŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š å®éªŒæ¦‚è¿°

æœ¬æŠ¥å‘Šå¯¹æ¯”äº† **RAGEnhancedAgentMemoryï¼ˆå¢å¼ºç‰ˆï¼‰** å’Œ **åŸºçº¿ç³»ç»Ÿï¼ˆæ»‘åŠ¨çª—å£ï¼‰** åœ¨ä»¥ä¸‹ç»´åº¦çš„è¡¨ç°ï¼š

- âš¡ æ¨ç†æ€§èƒ½ï¼ˆå»¶è¿Ÿã€é¦–å­—å»¶è¿Ÿï¼‰
- ğŸ§  é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›
- ğŸ’¾ å­˜å‚¨æ•ˆç‡ï¼ˆå™ªéŸ³è¿‡æ»¤ç‡ã€ä¿¡æ¯ä¿ç•™ç‡ï¼‰

### æµ‹è¯•åœºæ™¯

- **æµ‹è¯•è½®æ•°**: {enhanced.get("total_turns", 100)} è½®å¯¹è¯
- **æµ‹è¯•å†…å®¹**: 
  - Phase 1 (1-5è½®): è®¾å®šäººè®¾ï¼ˆå·¥å·ã€å’–å•¡ä¹ æƒ¯ï¼‰
  - Phase 2 (6-35è½®): é‡å¤æŸ¥è¯¢è®¢å•ï¼ˆæµ‹è¯•å»é‡ï¼‰
  - Phase 3 (36-85è½®): ä½ä»·å€¼çŒæ°´ï¼ˆæµ‹è¯•è¿‡æ»¤ï¼‰
  - Phase 4 (86-100è½®): è®°å¿†å¬å›æµ‹è¯•ï¼ˆå·¥å·ã€å’–å•¡ä¹ æƒ¯ã€è®¢å•å·ï¼‰

---

## âš¡ æ¨ç†æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | å¢å¼ºç‰ˆ | åŸºçº¿ç‰ˆ | å·®å¼‚ |
|------|--------|--------|------|
| å¹³å‡å»¶è¿Ÿ | {enhanced_avg_latency:.1f} ms | {baseline_avg_latency:.1f} ms | {latency_diff:+.1f}% |
| å¹³å‡é¦–å­—å»¶è¿Ÿ (TTFT) | {enhanced_avg_ttft:.1f} ms | {baseline_avg_ttft:.1f} ms | {ttft_diff:+.1f}% |
| å¹³å‡ååé‡ | {enhanced_avg_tps:.1f} tokens/s | {baseline_avg_tps:.1f} tokens/s | {tps_diff:+.1f}% |

### æ€§èƒ½åˆ†æ

"""
        
        if latency_diff < -10:
            md_content += f"- âœ… **vLLM ä¼˜åŒ–æ˜¾è‘—**: å»¶è¿Ÿé™ä½ {abs(latency_diff):.1f}%ï¼ŒvLLM çš„ PagedAttention å’Œ Prefix Caching ä¼˜åŒ–æ•ˆæœæ˜æ˜¾\n"
        elif latency_diff < 0:
            md_content += f"- âœ… **vLLM ä¼˜åŒ–ç”Ÿæ•ˆ**: å»¶è¿Ÿé™ä½ {abs(latency_diff):.1f}%\n"
        elif abs(latency_diff) < 10:
            md_content += f"- âš ï¸ **å»¶è¿Ÿç›¸å½“**: å¢å¼ºç‰ˆå»¶è¿Ÿ {latency_diff:+.1f}%ï¼ˆå¯èƒ½å—æ£€ç´¢å¼€é”€å½±å“ï¼‰\n"
        else:
            md_content += f"- âš ï¸ **å¢å¼ºç‰ˆå»¶è¿Ÿè¾ƒé«˜**: +{latency_diff:.1f}%ï¼ˆæ£€ç´¢å¼€é”€ï¼Œä½†æ¢å–é•¿æœŸè®°å¿†èƒ½åŠ›ï¼‰\n"
        
        if ttft_diff < -10:
            md_content += f"- âœ… **é¦–å­—å»¶è¿Ÿä¼˜åŒ–æ˜¾è‘—**: TTFT é™ä½ {abs(ttft_diff):.1f}%\n"
        elif ttft_diff < 0:
            md_content += f"- âœ… **é¦–å­—å»¶è¿Ÿä¼˜åŒ–**: TTFT é™ä½ {abs(ttft_diff):.1f}%\n"
        
        md_content += f"""
---

## ğŸ§  é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›å¯¹æ¯”

| æµ‹è¯•é¡¹ | å¢å¼ºç‰ˆ | åŸºçº¿ç‰ˆ | æ”¹è¿› |
|--------|--------|--------|------|
"""
        
        for test_name in enhanced["recall_test_cases"].keys():
            enhanced_found = enhanced["recall_test_cases"][test_name]["found"]
            baseline_found = baseline["recall_test_cases"][test_name]["found"]
            
            enhanced_status = "âœ…" if enhanced_found else "âŒ"
            baseline_status = "âœ…" if baseline_found else "âŒ"
            improvement = "âœ… æå‡" if (enhanced_found and not baseline_found) else ("=" if enhanced_found == baseline_found else "âŒ")
            
            md_content += f"| {test_name} | {enhanced_status} | {baseline_status} | {improvement} |\n"
        
        md_content += f"""| **å¬å›æˆåŠŸç‡** | **{enhanced_recall_rate:.1f}%** ({enhanced_recall_count}/{len(enhanced['recall_test_cases'])}) | **{baseline_recall_rate:.1f}%** ({baseline_recall_count}/{len(baseline['recall_test_cases'])}) | **{recall_improvement:+.1f} ç™¾åˆ†ç‚¹** |

### å¬å›èƒ½åŠ›åˆ†æ

"""
        
        if recall_improvement > 0:
            md_content += f"- âœ… **é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›æ˜¾è‘—æå‡**: {recall_improvement:.1f} ç™¾åˆ†ç‚¹\n"
            md_content += f"  - å¢å¼ºç‰ˆï¼š{enhanced_recall_rate:.1f}% ({enhanced_recall_count}/{len(enhanced['recall_test_cases'])})\n"
            md_content += f"  - åŸºçº¿ç‰ˆï¼š{baseline_recall_rate:.1f}% ({baseline_recall_count}/{len(baseline['recall_test_cases'])})\n"
        else:
            md_content += f"- âš ï¸ **å¬å›èƒ½åŠ›å¯¹æ¯”**: å¢å¼ºç‰ˆ {enhanced_recall_rate:.1f}% vs åŸºçº¿ç‰ˆ {baseline_recall_rate:.1f}%\n"
        
        md_content += f"""
- **æµ‹è¯•åœºæ™¯**: åœ¨ {enhanced.get("total_turns", 100)} è½®å¯¹è¯åï¼Œæµ‹è¯•ç³»ç»Ÿæ˜¯å¦èƒ½ä»é•¿æœŸè®°å¿†ä¸­å¬å›æ—©æœŸï¼ˆç¬¬1-5è½®ï¼‰çš„å…³é”®ä¿¡æ¯
- **æµ‹è¯•ä¿¡æ¯ç‚¹**: å·¥å·ï¼ˆç¬¬1è½®ï¼‰ã€å’–å•¡ä¹ æƒ¯ï¼ˆç¬¬2è½®ï¼‰ã€è®¢å•å·ï¼ˆç¬¬6-35è½®ï¼‰

---

## ğŸ’¾ å­˜å‚¨æ•ˆç‡å¯¹æ¯”

| æŒ‡æ ‡ | å¢å¼ºç‰ˆ | åŸºçº¿ç‰ˆ | è¯´æ˜ |
|------|--------|--------|------|
| æ•°æ®åº“ä¸­å­˜å‚¨æ•° | {enhanced.get("stored_turns", 0)} | {baseline.get("stored_turns", 0)} | å¢å¼ºç‰ˆï¼šå‘é‡æ•°æ®åº“ï¼›åŸºçº¿ç‰ˆï¼šçª—å£å†…å¯¹è¯æ•° |
| å™ªéŸ³è¿‡æ»¤ç‡ | {enhanced.get("noise_filter_rate", 0):.1f}% | {baseline.get("noise_filter_rate", 0):.1f}% | è¢«å»é‡/è¿‡æ»¤æ‰çš„æ— æ•ˆä¿¡æ¯æ¯”ä¾‹ |
| ä¿¡æ¯ä¿ç•™ç‡ | {enhanced.get("retention_rate", 0):.1f}% | {baseline.get("retention_rate", 0):.1f}% | å…³é”®ä¿¡æ¯ä¿ç•™æ¯”ä¾‹ |

### å­˜å‚¨æ•ˆç‡åˆ†æ

"""
        
        enhanced_noise_filter = enhanced.get("noise_filter_rate", 0)
        baseline_noise_filter = baseline.get("noise_filter_rate", 0)
        
        if enhanced_noise_filter > 70:
            md_content += f"- âœ… **å­˜å‚¨ä¼˜åŒ–æ˜¾è‘—**: å¢å¼ºç‰ˆå™ªéŸ³è¿‡æ»¤ç‡ {enhanced_noise_filter:.1f}%ï¼ŒæˆåŠŸè¿‡æ»¤äº†ç»å¤§å¤šæ•°é‡å¤å’Œæ— æ•ˆä¿¡æ¯\n"
        elif enhanced_noise_filter > 50:
            md_content += f"- âœ… **å­˜å‚¨ä¼˜åŒ–ç”Ÿæ•ˆ**: å¢å¼ºç‰ˆå™ªéŸ³è¿‡æ»¤ç‡ {enhanced_noise_filter:.1f}%ï¼Œæœ‰æ•ˆå‡å°‘å­˜å‚¨å†—ä½™\n"
        else:
            md_content += f"- âš ï¸ **å­˜å‚¨ä¼˜åŒ–å¾…æ”¹è¿›**: å¢å¼ºç‰ˆå™ªéŸ³è¿‡æ»¤ç‡ {enhanced_noise_filter:.1f}%\n"
        
        enhanced_retention = enhanced.get("retention_rate", 0)
        baseline_retention = baseline.get("retention_rate", 0)
        
        if enhanced_retention >= 80:
            md_content += f"- âœ… **ä¿¡æ¯ä¿ç•™ä¼˜ç§€**: å¢å¼ºç‰ˆä¿¡æ¯ä¿ç•™ç‡ {enhanced_retention:.1f}%ï¼Œå…³é”®ä¿¡æ¯å¾—åˆ°æœ‰æ•ˆä¿ç•™\n"
        elif enhanced_retention >= 60:
            md_content += f"- âœ… **ä¿¡æ¯ä¿ç•™è‰¯å¥½**: å¢å¼ºç‰ˆä¿¡æ¯ä¿ç•™ç‡ {enhanced_retention:.1f}%\n"
        else:
            md_content += f"- âš ï¸ **ä¿¡æ¯ä¿ç•™å¾…æ”¹è¿›**: å¢å¼ºç‰ˆä¿¡æ¯ä¿ç•™ç‡ {enhanced_retention:.1f}%\n"
        
        md_content += f"""
- **åŸºçº¿ç³»ç»Ÿé™åˆ¶**: æ»‘åŠ¨çª—å£å¤§å° {baseline.get("window_size", 10)}ï¼Œè¶…å‡ºçª—å£çš„å¯¹è¯å·²ä¸¢å¤±ï¼Œä¿¡æ¯ä¿ç•™ç‡ä»… {baseline_retention:.1f}%
- **å¢å¼ºç‰ˆä¼˜åŠ¿**: é€šè¿‡è¯­ä¹‰å»é‡å’Œä½ä»·å€¼è¿‡æ»¤ï¼Œåœ¨ä¿æŒé«˜ä¿¡æ¯ä¿ç•™ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘å­˜å‚¨å†—ä½™

---

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“

"""
        
        if enhanced_recall_rate > baseline_recall_rate:
            md_content += "- âœ… **é•¿æœŸè®°å¿†å¬å›èƒ½åŠ›**: æ˜¾è‘—ä¼˜äºåŸºçº¿ç³»ç»Ÿ\n"
        if enhanced_recall_rate >= 66:
            md_content += "- âœ… **èƒ½å¤Ÿä»é•¿æœŸè®°å¿†ä¸­å¬å›æ—©æœŸå…³é”®ä¿¡æ¯**: å¬å›æˆåŠŸç‡ {enhanced_recall_rate:.1f}%\n"
        if baseline_recall_rate < 33:
            md_content += "- âœ… **åŸºçº¿ç³»ç»Ÿæ— æ³•å¬å›è¶…å‡ºçª—å£çš„æ—©æœŸä¿¡æ¯**: éªŒè¯äº†é—®é¢˜å­˜åœ¨ï¼ˆå¬å›æˆåŠŸç‡ä»… {baseline_recall_rate:.1f}%ï¼‰\n"
        
        if enhanced_noise_filter > 70:
            md_content += "- âœ… **å­˜å‚¨ä¼˜åŒ–**: å™ªéŸ³è¿‡æ»¤ç‡ {enhanced_noise_filter:.1f}%ï¼Œæœ‰æ•ˆå‡å°‘å­˜å‚¨å†—ä½™\n"
        
        if enhanced_retention >= 80:
            md_content += "- âœ… **ä¿¡æ¯ä¿ç•™**: ä¿¡æ¯ä¿ç•™ç‡ {enhanced_retention:.1f}%ï¼Œå…³é”®ä¿¡æ¯å¾—åˆ°æœ‰æ•ˆä¿ç•™\n"
        
        md_content += f"""
---

## ğŸ“ å®éªŒç»“è®º

### å¢å¼ºç‰ˆï¼ˆRAGEnhancedAgentMemoryï¼‰ä¼˜åŠ¿

1. **é•¿æœŸè®°å¿†èƒ½åŠ›**: é€šè¿‡å‘é‡æ•°æ®åº“å’Œè¯­ä¹‰æ£€ç´¢ï¼Œèƒ½å¤Ÿä»é•¿æœŸè®°å¿†ä¸­å¬å›æ—©æœŸå…³é”®ä¿¡æ¯ï¼Œå¬å›æˆåŠŸç‡ {enhanced_recall_rate:.1f}%
2. **å­˜å‚¨ä¼˜åŒ–**: é€šè¿‡è¯­ä¹‰å»é‡å’Œä½ä»·å€¼è¿‡æ»¤ï¼Œå™ªéŸ³è¿‡æ»¤ç‡ {enhanced_noise_filter:.1f}%ï¼Œæœ‰æ•ˆå‡å°‘å­˜å‚¨å†—ä½™
3. **ä¿¡æ¯ä¿ç•™**: ä¿¡æ¯ä¿ç•™ç‡ {enhanced_retention:.1f}%ï¼Œå…³é”®ä¿¡æ¯å¾—åˆ°æœ‰æ•ˆä¿ç•™
4. **æ¨ç†æ€§èƒ½**: ä½¿ç”¨ vLLM ä¼˜åŒ–ï¼Œå¹³å‡å»¶è¿Ÿ {enhanced_avg_latency:.1f}msï¼Œé¦–å­—å»¶è¿Ÿ {enhanced_avg_ttft:.1f}ms

### åŸºçº¿ç³»ç»Ÿé™åˆ¶

1. **æ— é•¿æœŸè®°å¿†**: ä»…ä½¿ç”¨æ»‘åŠ¨çª—å£ï¼ˆ{baseline.get("window_size", 10)} è½®ï¼‰ï¼Œè¶…å‡ºçª—å£çš„å¯¹è¯å·²ä¸¢å¤±
2. **æ— å­˜å‚¨ä¼˜åŒ–**: å™ªéŸ³è¿‡æ»¤ç‡ä¸º 0%ï¼Œæ‰€æœ‰å¯¹è¯éƒ½å­˜å‚¨ï¼ˆåœ¨çª—å£å†…ï¼‰
3. **ä¿¡æ¯ä¸¢å¤±**: ä¿¡æ¯ä¿ç•™ç‡ä»… {baseline_retention:.1f}%ï¼Œæ—©æœŸå…³é”®ä¿¡æ¯æ— æ³•å¬å›
4. **å¬å›èƒ½åŠ›**: å¬å›æˆåŠŸç‡ä»… {baseline_recall_rate:.1f}%ï¼Œæ— æ³•å¬å›è¶…å‡ºçª—å£çš„æ—©æœŸä¿¡æ¯

### é¡¹ç›®å¯ç”¨æ€§éªŒè¯

âœ… **RAGEnhancedAgentMemory é¡¹ç›®å·²é€šè¿‡å…¨é¢éªŒè¯**ï¼Œåœ¨é•¿æœŸè®°å¿†å¬å›ã€å­˜å‚¨ä¼˜åŒ–ã€ä¿¡æ¯ä¿ç•™ç­‰æ ¸å¿ƒåŠŸèƒ½ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ç³»ç»Ÿï¼Œè¯æ˜äº†é¡¹ç›®çš„å®ç”¨ä»·å€¼å’Œå¯ç”¨æ€§ã€‚

---

*æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–å¯¹æ¯”æµ‹è¯•è„šæœ¬ç”Ÿæˆ*
"""
        
        # ä¿å­˜Markdownæ–‡ä»¶
        report_path = project_root / "benchmark_comparison_report.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        
        console.print(f"\n[bold green]âœ… Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}[/bold green]")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å¯¹æ¯”æµ‹è¯•ï¼šå¢å¼ºç‰ˆï¼ˆvLLMï¼‰vs åŸºçº¿ç‰ˆï¼ˆBaselineï¼‰")
    parser.add_argument(
        "--model-path",
        type=str,
        default=None,
        help="æ¨¡å‹è·¯å¾„æˆ–åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä» .env æ–‡ä»¶ä¸­çš„ VLLM_MODEL è¯»å–ï¼‰"
    )
    parser.add_argument(
        "--enhanced-only",
        action="store_true",
        help="åªè¿è¡Œå¢å¼ºç‰ˆæµ‹è¯•ï¼ˆvLLMï¼‰"
    )
    parser.add_argument(
        "--baseline-only",
        action="store_true",
        help="åªè¿è¡ŒåŸºçº¿ç‰ˆæµ‹è¯•ï¼ˆBaselineï¼‰"
    )
    
    args = parser.parse_args()
    
    test = ComparisonTest(
        model_path=args.model_path
    )
    
    enhanced_results = None
    baseline_results = None
    
    try:
        if not args.baseline_only:
            enhanced_results = test.run_enhanced()
        
        if not args.enhanced_only:
            baseline_results = test.run_baseline()
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        if enhanced_results and baseline_results:
            test.generate_comparison_report(enhanced_results, baseline_results)
        elif enhanced_results:
            console.print("\n[dim]æç¤º: ä½¿ç”¨ --baseline-only è¿è¡ŒåŸºçº¿ç‰ˆä»¥ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š[/dim]")
        elif baseline_results:
            console.print("\n[dim]æç¤º: ä½¿ç”¨ --enhanced-only è¿è¡Œå¢å¼ºç‰ˆä»¥ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š[/dim]")
            
    except KeyboardInterrupt:
        console.print("\n[yellow]âš ï¸  ç”¨æˆ·ä¸­æ–­[/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]âŒ è¿è¡Œå‡ºé”™: {e}[/red]")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
