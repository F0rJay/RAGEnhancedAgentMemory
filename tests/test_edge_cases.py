"""
è¾¹ç•Œæ¡ä»¶æµ‹è¯•

æµ‹è¯•å„ä¸ªæ¨¡å—åœ¨è¾¹ç•Œæƒ…å†µä¸‹çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬ï¼š
- ç©ºè¾“å…¥å¤„ç†
- None å€¼å¤„ç†
- æžç«¯å€¼å¤„ç†
- ç±»åž‹é”™è¯¯å¤„ç†
- å¼‚å¸¸æƒ…å†µå¤„ç†
"""

import pytest
from unittest.mock import Mock, patch
from typing import Dict, Any, List


# ==================== ShortTermMemory è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_short_term_memory_empty_inputs():
    """æµ‹è¯•çŸ­æœŸè®°å¿†å¤„ç†ç©ºè¾“å…¥"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    # ç©ºå­—ç¬¦ä¸²è¾“å…¥
    memory.add_conversation_turn(human_message="", ai_message="å›žç­”")
    memory.add_conversation_turn(human_message="é—®é¢˜", ai_message="")

    # ç©ºä¸Šä¸‹æ–‡åº”è¯¥è¿”å›žç©ºç»“æžœ
    empty_context = memory.get_recent_context()
    assert "turn_count" in empty_context


def test_short_term_memory_max_turns_zero():
    """æµ‹è¯•æœ€å¤§è½®æ•°ä¸º0çš„æƒ…å†µ"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=0)

    memory.add_conversation_turn(human_message="é—®é¢˜", ai_message="å›žç­”")

    context = memory.get_recent_context()
    # å³ä½¿max_turns=0ï¼Œä¹Ÿåº”è¯¥èƒ½å¤„ç†
    assert isinstance(context, dict)


def test_short_term_memory_very_large_input():
    """æµ‹è¯•éžå¸¸å¤§çš„è¾“å…¥"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    # éžå¸¸å¤§çš„å­—ç¬¦ä¸²
    large_message = "x" * 100000
    memory.add_conversation_turn(
        human_message=large_message,
        ai_message="å›žç­”"
    )

    context = memory.get_recent_context()
    assert context["turn_count"] >= 1


def test_short_term_memory_special_characters():
    """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    special_message = "æµ‹è¯•ï¼š\n\næ¢è¡Œ\tåˆ¶è¡¨ç¬¦\nç‰¹æ®Šå­—ç¬¦!@#$%^&*()"
    memory.add_conversation_turn(
        human_message=special_message,
        ai_message="å›žç­”"
    )

    context = memory.get_recent_context()
    assert context["turn_count"] >= 1


# ==================== Routing è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_routing_empty_query():
    """æµ‹è¯•è·¯ç”±å¤„ç†ç©ºæŸ¥è¯¢"""
    from src.memory.routing import MemoryRouter, RoutingContext
    from src.memory.short_term import ShortTermMemory
    from unittest.mock import Mock

    router = MemoryRouter()
    short_memory = ShortTermMemory()
    long_memory = Mock()

    context = RoutingContext(
        query="",
        short_term_memory=short_memory,
        long_term_memory=long_memory,
    )

    # ç©ºæŸ¥è¯¢åº”è¯¥èƒ½å¤„ç†ï¼Œä¸ä¼šæŠ›å‡ºå¼‚å¸¸
    result = router.route(context)
    assert result is not None
    assert result.decision is not None


def test_routing_none_values():
    """æµ‹è¯•è·¯ç”±å¤„ç†Noneå€¼"""
    from src.memory.routing import MemoryRouter, RoutingContext
    from src.memory.short_term import ShortTermMemory
    from unittest.mock import Mock

    router = MemoryRouter()
    short_memory = ShortTermMemory()
    long_memory = Mock()

    context = RoutingContext(
        query="æµ‹è¯•",
        short_term_memory=short_memory,
        long_term_memory=long_memory,
        recent_relevance_score=None,
        previous_retrieval_time=None,
        query_complexity=None,
    )

    result = router.route(context)
    assert result is not None


def test_routing_extreme_relevance_scores():
    """æµ‹è¯•æžç«¯ç›¸å…³æ€§è¯„åˆ†"""
    from src.memory.routing import MemoryRouter, RoutingContext
    from src.memory.short_term import ShortTermMemory
    from unittest.mock import Mock

    router = MemoryRouter()
    short_memory = ShortTermMemory()
    long_memory = Mock()

    # æžä½Žè¯„åˆ†
    context_low = RoutingContext(
        query="æµ‹è¯•",
        short_term_memory=short_memory,
        long_term_memory=long_memory,
        recent_relevance_score=0.0,
    )
    result_low = router.route(context_low)
    assert result_low is not None

    # æžé«˜è¯„åˆ†
    context_high = RoutingContext(
        query="æµ‹è¯•",
        short_term_memory=short_memory,
        long_term_memory=long_memory,
        recent_relevance_score=1.0,
    )
    result_high = router.route(context_high)
    assert result_high is not None


# ==================== HybridRetriever è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_hybrid_retriever_invalid_weights():
    """æµ‹è¯•æ··åˆæ£€ç´¢å™¨æ— æ•ˆæƒé‡"""
    from src.retrieval.hybrid import HybridRetriever
    from unittest.mock import Mock

    long_term_memory = Mock()

    # æƒé‡ä¹‹å’Œä¸ç­‰äºŽ1.0
    with pytest.raises(ValueError, match="ä¹‹å’Œå¿…é¡»ç­‰äºŽ 1.0"):
        HybridRetriever(
            long_term_memory=long_term_memory,
            vector_weight=0.5,
            keyword_weight=0.6,
        )


def test_hybrid_retriever_zero_weights():
    """æµ‹è¯•æ··åˆæ£€ç´¢å™¨é›¶æƒé‡"""
    from src.retrieval.hybrid import HybridRetriever
    from unittest.mock import Mock

    long_term_memory = Mock()

    # ä¸€ä¸ªæƒé‡ä¸º0
    retriever = HybridRetriever(
        long_term_memory=long_term_memory,
        vector_weight=1.0,
        keyword_weight=0.0,
    )

    assert retriever.vector_weight == 1.0
    assert retriever.keyword_weight == 0.0


def test_hybrid_retriever_empty_query():
    """æµ‹è¯•æ··åˆæ£€ç´¢å™¨ç©ºæŸ¥è¯¢"""
    from src.retrieval.hybrid import HybridRetriever
    from unittest.mock import Mock, MagicMock

    long_term_memory = Mock()
    long_term_memory.search.return_value = []

    retriever = HybridRetriever(
        long_term_memory=long_term_memory,
        vector_weight=0.7,
        keyword_weight=0.3,
    )

    # ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›žç©ºç»“æžœ
    results = retriever.retrieve("", top_k=5)
    assert results == []


def test_hybrid_retriever_zero_top_k():
    """æµ‹è¯•æ··åˆæ£€ç´¢å™¨top_k=0"""
    from src.retrieval.hybrid import HybridRetriever
    from unittest.mock import Mock

    long_term_memory = Mock()
    long_term_memory.search.return_value = []

    retriever = HybridRetriever(
        long_term_memory=long_term_memory,
    )

    results = retriever.retrieve("æµ‹è¯•", top_k=0)
    assert results == []


# ==================== Config è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_config_invalid_env_values():
    """æµ‹è¯•é…ç½®å¤„ç†æ— æ•ˆçŽ¯å¢ƒå˜é‡å€¼"""
    import os
    from src.config import get_settings

    # ä¿å­˜åŽŸå§‹å€¼
    original_max_len = os.environ.get("VLLM_MAX_MODEL_LEN")

    try:
        # è®¾ç½®æ— æ•ˆå€¼ï¼ˆéžæ•°å­—ï¼‰
        os.environ["VLLM_MAX_MODEL_LEN"] = "invalid"

        # åº”è¯¥èƒ½å¤„ç†æ— æ•ˆå€¼ï¼ˆä½¿ç”¨é»˜è®¤å€¼æˆ–æŠ›å‡ºå¼‚å¸¸ï¼‰
        try:
            settings = get_settings()
            # å¦‚æžœèƒ½èŽ·å–è®¾ç½®ï¼Œåº”è¯¥ä½¿ç”¨é»˜è®¤å€¼
            assert isinstance(settings.vllm_max_model_len, int)
        except (ValueError, TypeError):
            # å¦‚æžœæŠ›å‡ºå¼‚å¸¸ä¹Ÿæ˜¯å¯ä»¥æŽ¥å—çš„
            pass
    finally:
        # æ¢å¤åŽŸå§‹å€¼
        if original_max_len is not None:
            os.environ["VLLM_MAX_MODEL_LEN"] = original_max_len
        elif "VLLM_MAX_MODEL_LEN" in os.environ:
            del os.environ["VLLM_MAX_MODEL_LEN"]


def test_config_negative_values():
    """æµ‹è¯•é…ç½®å¤„ç†è´Ÿæ•°å€¼"""
    import os
    from src.config import get_settings

    original_util = os.environ.get("VLLM_GPU_MEMORY_UTILIZATION")

    try:
        # è®¾ç½®è´Ÿæ•°å€¼
        os.environ["VLLM_GPU_MEMORY_UTILIZATION"] = "-0.5"

        settings = get_settings()
        # åº”è¯¥è¢«éªŒè¯æˆ–ä½¿ç”¨é»˜è®¤å€¼
        assert settings.vllm_gpu_memory_utilization >= 0.0
    finally:
        if original_util is not None:
            os.environ["VLLM_GPU_MEMORY_UTILIZATION"] = original_util
        elif "VLLM_GPU_MEMORY_UTILIZATION" in os.environ:
            del os.environ["VLLM_GPU_MEMORY_UTILIZATION"]


# ==================== LongTermMemory è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_long_term_memory_empty_content():
    """æµ‹è¯•é•¿æœŸè®°å¿†å¤„ç†ç©ºå†…å®¹"""
    from src.memory.long_term import MemoryItem

    # ç©ºå†…å®¹
    item = MemoryItem(
        id="test-id",
        content="",
        memory_type="conversation",
        metadata={}
    )

    assert item.content == ""
    assert item.memory_type == "conversation"


def test_long_term_memory_none_metadata():
    """æµ‹è¯•é•¿æœŸè®°å¿†å¤„ç†Noneå…ƒæ•°æ®"""
    from src.memory.long_term import MemoryItem

    # metadataåº”è¯¥ä½¿ç”¨é»˜è®¤å€¼ï¼Œä¸æŽ¥å—None
    item = MemoryItem(
        id="test-id",
        content="æµ‹è¯•",
        memory_type="conversation",
        metadata={}  # ç©ºå­—å…¸è€Œä¸æ˜¯None
    )

    assert item.metadata == {}


# ==================== Evaluation è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_evaluation_empty_lists():
    """æµ‹è¯•è¯„ä¼°æ¨¡å—å¤„ç†ç©ºåˆ—è¡¨"""
    from src.evaluation.ragas_eval import EvaluationResult

    # è¯„ä¼°ç»“æžœåº”è¯¥èƒ½å¤„ç†å„ç§å€¼
    result = EvaluationResult(
        context_recall=0.0,
        context_precision=0.0,
        faithfulness=0.0,
        answer_relevancy=0.0,
        overall_score=0.0,
    )

    assert result.overall_score == 0.0


def test_evaluation_extreme_scores():
    """æµ‹è¯•è¯„ä¼°æ¨¡å—å¤„ç†æžç«¯è¯„åˆ†"""
    from src.evaluation.ragas_eval import EvaluationResult

    # æœ€å°åˆ†æ•°
    result_min = EvaluationResult(
        context_recall=0.0,
        context_precision=0.0,
        faithfulness=0.0,
        answer_relevancy=0.0,
        overall_score=0.0,
    )

    # æœ€å¤§åˆ†æ•°
    result_max = EvaluationResult(
        context_recall=1.0,
        context_precision=1.0,
        faithfulness=1.0,
        answer_relevancy=1.0,
        overall_score=1.0,
    )

    assert result_min.overall_score == 0.0
    assert result_max.overall_score == 1.0


# ==================== Reranker è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_reranker_empty_documents():
    """æµ‹è¯•é‡æŽ’åºå™¨å¤„ç†ç©ºæ–‡æ¡£åˆ—è¡¨"""
    from src.retrieval.reranker import RerankedResult

    # é‡æŽ’åºç»“æžœåº”è¯¥èƒ½å¤„ç†å„ç§æƒ…å†µ
    result = RerankedResult(
        content="",
        original_score=0.0,
        rerank_score=0.0,
        metadata={},
        rank_change=0,
    )

    assert result.content == ""


def test_reranker_extreme_scores():
    """æµ‹è¯•é‡æŽ’åºå™¨å¤„ç†æžç«¯è¯„åˆ†"""
    from src.retrieval.reranker import RerankedResult

    # æœ€å°è¯„åˆ†
    result_min = RerankedResult(
        content="æµ‹è¯•",
        original_score=0.0,
        rerank_score=0.0,
        metadata={},
        rank_change=0,
    )

    # æœ€å¤§è¯„åˆ†
    result_max = RerankedResult(
        content="æµ‹è¯•",
        original_score=1.0,
        rerank_score=1.0,
        metadata={},
        rank_change=0,
    )

    assert result_min.rerank_score == 0.0
    assert result_max.rerank_score == 1.0


# ==================== State è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_agent_state_empty_fields():
    """æµ‹è¯•AgentStateå¤„ç†ç©ºå­—æ®µ"""
    from src.graph.state import AgentState

    state: AgentState = {
        "input": "",
        "chat_history": [],
        "documents": [],
        "document_metadata": [],
        "generation": "",
        "relevance_score": "",
        "hallucination_score": "",
        "retry_count": 0,
    }

    assert state["input"] == ""
    assert len(state["chat_history"]) == 0
    assert len(state["documents"]) == 0


def test_agent_state_none_fields():
    """æµ‹è¯•AgentStateå¤„ç†Noneå­—æ®µï¼ˆåœ¨å…è®¸çš„æƒ…å†µä¸‹ï¼‰"""
    from src.graph.state import AgentState

    # æŸäº›å­—æ®µå¯ä»¥æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œä½†ä¸åº”è¯¥æ˜¯Noneï¼ˆç±»åž‹å®šä¹‰ä¸å…è®¸ï¼‰
    state: AgentState = {
        "input": "æµ‹è¯•",
        "chat_history": [],
        "documents": [],
        "document_metadata": [],
        "generation": "",
        "relevance_score": "yes",
        "hallucination_score": "grounded",
        "retry_count": 0,
    }

    assert state["input"] == "æµ‹è¯•"


# ==================== ç»¼åˆè¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

def test_concurrent_empty_operations():
    """æµ‹è¯•å¹¶å‘ç©ºæ“ä½œ"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    # å¿«é€Ÿè¿žç»­æ·»åŠ ç©ºæ“ä½œ
    for _ in range(100):
        memory.add_conversation_turn(human_message="", ai_message="")

    context = memory.get_recent_context()
    assert isinstance(context, dict)


def test_unicode_special_characters():
    """æµ‹è¯•Unicodeç‰¹æ®Šå­—ç¬¦å¤„ç†"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    # å„ç§Unicodeå­—ç¬¦
    unicode_messages = [
        "ä¸­æ–‡æµ‹è¯•",
        "ðŸš€ emojiæµ‹è¯•",
        "é˜¿æ‹‰ä¼¯æ–‡: Ù…Ø±Ø­Ø¨Ø§",
        "æ—¥æ–‡: ã“ã‚“ã«ã¡ã¯",
        "ä¿„æ–‡: ÐŸÑ€Ð¸Ð²ÐµÑ‚",
    ]

    for msg in unicode_messages:
        memory.add_conversation_turn(
            human_message=msg,
            ai_message="å›žç­”"
        )

    context = memory.get_recent_context()
    assert context["turn_count"] >= len(unicode_messages)


def test_very_long_metadata():
    """æµ‹è¯•éžå¸¸é•¿çš„å…ƒæ•°æ®"""
    from src.memory.long_term import MemoryItem

    # åˆ›å»ºåŒ…å«å¤§é‡æ•°æ®çš„å…ƒæ•°æ®
    large_metadata = {
        "key" + str(i): "value" * 100 for i in range(100)
    }

    item = MemoryItem(
        id="test-id",
        content="æµ‹è¯•",
        memory_type="conversation",
        metadata=large_metadata
    )

    assert len(item.metadata) == 100


def test_nested_metadata():
    """æµ‹è¯•åµŒå¥—å…ƒæ•°æ®"""
    from src.memory.long_term import MemoryItem

    nested_metadata = {
        "level1": {
            "level2": {
                "level3": "value"
            }
        }
    }

    item = MemoryItem(
        id="test-id",
        content="æµ‹è¯•",
        memory_type="conversation",
        metadata=nested_metadata
    )

    assert item.metadata["level1"]["level2"]["level3"] == "value"


def test_type_coercion():
    """æµ‹è¯•ç±»åž‹è½¬æ¢è¾¹ç•Œæƒ…å†µ"""
    from src.memory.short_term import ShortTermMemory

    memory = ShortTermMemory(max_turns=10)

    # æµ‹è¯•ä¸åŒç±»åž‹çš„æ•°æ®ï¼ˆåº”è¯¥éƒ½èƒ½è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰
    memory.add_conversation_turn(
        human_message=str(123),  # æ•°å­—
        ai_message=str(True)  # å¸ƒå°”å€¼
    )

    context = memory.get_recent_context()
    assert context["turn_count"] >= 1


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
